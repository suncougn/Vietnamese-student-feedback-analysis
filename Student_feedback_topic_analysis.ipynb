{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc301fe0-4a57-478d-b495-14af49ad5abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Local libraries\n",
    "from data_processor_pipeline.cleaner import *\n",
    "from data_processor_pipeline.custom_dataset import *\n",
    "from metrics.plot_confusion_matrix import plot_cfs_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc92ab23-56b8-4fde-b57f-16a0916d9482",
   "metadata": {},
   "source": [
    "# Data_preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cc7fdf-c45f-491f-9d1f-c9efa3b623d1",
   "metadata": {},
   "source": [
    "## Read data and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c89d3b9-1cdb-4448-85cb-8eb5e69ce913",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('vietnamese_student_feedbacks.csv', encoding='utf-8-sig')\n",
    "data_processor=data_clean()\n",
    "data['sentence'] = data['sentence'].map(lambda x:data_processor.clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47e25e98-ca4e-4d80-85fe-4851be39a34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data['combined_label']=list(zip(data['sentiment'], data['topic']))\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['sentence'].reset_index(drop=True).to_list(), \n",
    "                                                    data['combined_label'].reset_index(drop=True).to_list(), \n",
    "                                                    test_size=0.1, \n",
    "                                                    stratify=data['topic'],\n",
    "                                                    random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bbb3fb6-6646-4823-9d1d-c59c6eba0a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, y_train_topic = zip(*y_train)\n",
    "_, y_val_topic = zip(*y_val)\n",
    "_, y_test_topic = zip(*y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d1214ba-a84f-4db0-aa5c-980d9c62cdb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3]), array([9392, 2483,  578,  648], dtype=int64))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train_topic, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb500ec-b90c-416f-ab90-d62ce3d096fe",
   "metadata": {},
   "source": [
    "## Create dataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed7e9be-bdfb-4e95-9c8b-18342c466202",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_topic = Custom_Dataset(X_train, torch.Tensor(y_train_topics, dtype=torch.long), file_path='vocab.pkl', is_save_vocab=False)\n",
    "val_dataset_topic =Custom_Dataset(X_val, y_val_topic, file_path='vocab.pkl', is_save_vocab=False, max_length=train_dateset_topic.max_length)\n",
    "test_dataset_topic = Custom_Dataset(X_test, y_test_topic, file_path='vocab.pkl', is_save_vocab=False, max_length=train_dataset_topic.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7688f6-45ec-4851-9365-4ecb3ba343af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader_topic=DataLoader(train_dataset_topic, batch_size=16, shuffle=True)\n",
    "val_dataloader_topic=DataLoader(val_dataset_topic, batch_size=16, shuffle=True)\n",
    "test_dataloader_topic=DataLoader(test_dataset_topic, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2359b4-0cd9-4ebd-9380-a43ff011a3d1",
   "metadata": {},
   "source": [
    "# DL_model for topic classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b86f128-ac89-4d78-959b-19d14d6d4134",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ca7239-15bb-4198-a129-1aad9729eba2",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbfaf266-ff27-4959-8bdc-a5f6ec89021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from build_model.build_rnn import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from training.trainer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d405497-e1b7-46d0-a694-73fbbc7ae27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_rnn = RNN(vocab_size=5000,\n",
    "                embedding_dim=128,\n",
    "                num_layers=1,\n",
    "                activation=None,\n",
    "                batch_normalization = True,\n",
    "                bidirectional=False,\n",
    "                output_dim=4\n",
    "               )\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_RNN=optim.Adam(model_rnn.parameters(), lr=0.01)\n",
    "epochs=5\n",
    "trainer=trainer()\n",
    "log_dir='logs/RNN_topic'\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "writer=SummaryWriter(log_dir='log_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f41e27a5-b178-4806-a3ad-02c3c2baf1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (embedding): Embedding(5000, 128)\n",
      "  (rnn): RNN(128, 64, dropout=0.2)\n",
      "  (dense1): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (dense2): Linear(in_features=64, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "best_Acc_RNN=0\n",
    "for epoch in epochs:\n",
    "    trainer.train(model_rnn, \n",
    "                  train_dataloader_topic,\n",
    "                  epoch,\n",
    "                  epochs,\n",
    "                  writer,\n",
    "                  criterion,\n",
    "                  optimizer_RNN,\n",
    "                  device\n",
    "                 )\n",
    "    val_loss, val_acc = trainer.validation(model_rnn, val_dataloader_topic, criterion, device)\n",
    "    print(f'VALIDATION | Epoch: {epoch+1}/{epochs} | Loss: {val_loss:.4f} | Accuracy: {val_acc:.4f}')\n",
    "    writer.add_scalar('Val/Loss', val_loss, epoch+1)\n",
    "    writer.add_scalar('Val/Acc', val_acc, epoch+1)\n",
    "    checkpoint = {\n",
    "        'model_state_dict': model_rnn.state_dict(),\n",
    "        'epoch': epoch+1,\n",
    "        'optimizer_RNN': optimizer_RNN.state_dict()\n",
    "    }\n",
    "    os.makedir('model/RNN_topic', exists_ok=True)\n",
    "    torch.save(checkpoint, os.path.join('model/RNN_topic','last.pt'))\n",
    "    if val_acc>best_Acc_RNN:\n",
    "        torch.save(checkpoint, os.path.join('model/RNN_topic','best.pt'))\n",
    "        best_Acc_RNN=val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3bfb44-712b-46c9-a0a5-1202d977b332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.trainner import *\n",
    "from build_model.build_rnn import * \n",
    "trainer=trainer()\n",
    "deveice=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_state_dict=torch.load('model/RNN_topic/best.pt', map_location=device)\n",
    "model_rnn.load_state_dict(model_state_dict['model_state_dict'])\n",
    "result_RNN_on_test=trainer.evualuate(model_rnn, test_loader_topic, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
