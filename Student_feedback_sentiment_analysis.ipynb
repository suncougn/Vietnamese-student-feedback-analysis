{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f56e306-37d4-48d6-9282-2f907883a352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from data_processor_pipeline.cleaner import *\n",
    "from data_processor_pipeline.custom_dataset import *\n",
    "from metrics.plot_confusion_matrix import plot_cfs_matrix\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41beed1b-6904-402a-a5c0-4c313891d212",
   "metadata": {},
   "source": [
    "# Data_Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a2520f-e2a9-4578-8900-602d679b98e4",
   "metadata": {},
   "source": [
    "## Read data and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8524de17-c955-4fb2-9d83-ff06b600e2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('vietnamese_student_feedbacks.csv', encoding='utf-8-sig')\n",
    "data_processor=data_clean()\n",
    "data['sentence']=data['sentence'].map(lambda x: data_processor.clean_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3c8a72-ea4e-451a-ab73-e622278f80ac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Multi processiong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79b4561-24bf-462e-bdff-6dd149410bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Manager\n",
    "\n",
    "# Function to test multiprocessing\n",
    "def test(indices):\n",
    "    print(indices)\n",
    "\n",
    "indices: list[int] = list(range(0, 20))\n",
    "n_proc = 8\n",
    "processes: list[Process] = []\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    with Manager() as manager:\n",
    "        indices = manager.list(indices)  # Shared list between processes\n",
    "        for idx in range(n_proc):\n",
    "            p = Process(target=test, args=(indices,))  # Pass the shared list to each process\n",
    "            processes.append(p)\n",
    "        \n",
    "        # Start all processes\n",
    "        for p in processes:\n",
    "            p.start()\n",
    "        \n",
    "        # Wait for all processes to complete\n",
    "        for p in processes:\n",
    "            p.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6986d345-2ca4-439e-aeb3-9b6e27495358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import multiprocessing\n",
    "\n",
    "# Hàm thực hiện clean_text với đa luồng\n",
    "def apply_clean_text_parallel(df, column_name, clean_func):\n",
    "    # Số lượng luồng bằng số lõi CPU\n",
    "    num_threads = multiprocessing.cpu_count()\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        df[column_name] = list(executor.map(clean_func, df['sentence']))\n",
    "    \n",
    "    return df\n",
    "df = apply_clean_text_parallel(data, 'cleaned', data_processor.clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87733b0-737e-498d-985e-45a34ebe2e97",
   "metadata": {},
   "source": [
    "## Train_validation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17dde437-bcbc-46ee-9aed-c541415ef349",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data['combined_label']=list(zip(data[\"sentiment\"], data['topic']))\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['sentence'].reset_index(drop=True).to_list(),\n",
    "                                                    data['combined_label'].reset_index(drop=True).to_list(),\n",
    "                                                    test_size=0.1,\n",
    "                                                    stratify=data['topic'],\n",
    "                                                    random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48957cef-6e3d-4b91-bb51-8d42bffb4e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13101, 1456, 1618)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_val), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22832ce3-f75a-4dd6-95b6-fefcb8caa0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_sentiment, y_train_topic = zip(*y_train)\n",
    "y_val_sentiment, y_val_topic = zip(*y_val)\n",
    "y_test_sentiment, y_test_topic = zip(*y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926c057c-5dec-4830-a176-d08774d29337",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb492d1f-aa83-481a-8377-04fddf934ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_train_sentiment = pd.DataFrame(y_train_sentiment, columns=['y_train_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555043e7-3da5-4235-adec-bacfab94fb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate neutral comments\n",
    "neutral_indices = df_y_train_sentiment[df_y_train_sentiment['y_train_sentiment']==1].to_numpy().flatten()\n",
    "oversample_size = df_y_train_sentiment[df_y_train_sentiment['y_train_sentiment']==0].shape[0] - len(neutral_indices)\n",
    "\n",
    "# Over-sample the neutral comments\n",
    "oversampled_neutral_indices = resample(neutral_indices,\n",
    "                                       replace=True,\n",
    "                                       n_samples=oversample_size)\n",
    "\n",
    "# Combine the original sentences and labels with the oversampled data\n",
    "oversampled_neutral_sentences = np.array(X_train)[oversampled_neutral_indices]\n",
    "\n",
    "train_sentences_oversampled = np.concatenate([X_train, oversampled_neutral_sentences], axis=0)\n",
    "train_labels_oversampled = np.concatenate([y_train_sentiment, np.array([1] * oversample_size)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4fe64e-4341-4637-8f56-2bd5abd3ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampled_neutral_sentences = np.array(X_train)[oversampled_neutral_indices]\n",
    "\n",
    "train_sentences_oversampled = np.concatenate([X_train, oversampled_neutral_sentences], axis=0)\n",
    "train_labels_oversampled = pd.Series(train_labels_oversampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6720604f-86a0-4f08-a56d-a297b4a8c2ba",
   "metadata": {},
   "source": [
    "## Create dataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a6597c-68cf-4845-9984-2e974f0efd01",
   "metadata": {},
   "source": [
    "## Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8423db2-b5c6-4b33-a3a0-d89d55b3f8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_sentiment=Custom_Dataset(X_train, torch.tensor(y_train_sentiment, dtype=torch.long), file_path='vocab.pkl', is_save_vocab=False)\n",
    "val_dataset_sentiment=Custom_Dataset(X_val, y_val_sentiment, file_path='vocab.pkl', is_save_vocab=False, max_length=train_dataset_sentiment.max_length)\n",
    "test_dataset_sentiment=Custom_Dataset(X_test, y_test_sentiment, file_path='vocab.pkl', is_save_vocab=False, max_length=train_dataset_sentiment.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b29ae088-4342-4931-ba96-7779ac003f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_sentiment=DataLoader(train_dataset_sentiment, batch_size=16, shuffle=True)\n",
    "val_loader_sentiment=DataLoader(val_dataset_sentiment, batch_size=16, shuffle=True)\n",
    "test_loader_sentiment=DataLoader(test_dataset_sentiment, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950e4751-dbb7-4150-9997-29df4b99f861",
   "metadata": {},
   "source": [
    "# DL_model for sentiment classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05435a2e-e6eb-4e59-b17d-6749b8dc41bb",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71fd1eb-e1ab-4b82-bd18-3c670384b53d",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199e7341-6331-4278-90e8-c7e62f7aa98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from build_model.build_rnn import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from training.trainer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6672101d-b191-40e7-be2d-2c3eadf7aee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (embedding): Embedding(5000, 128)\n",
      "  (rnn): RNN(128, 64, dropout=0.2)\n",
      "  (dense1): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activation): ReLU()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (dense2): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_RNN=RNN(vocab_size=5000, embedding_dim=128, num_layers=1, activation=nn.ReLU(), batch_normalization=True, bidirectional=False).to(device)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer_RNN=optim.Adam(model_RNN.parameters(), lr=0.01)\n",
    "epochs=5\n",
    "trainer=trainer()\n",
    "log_dir='logs/RNN'\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "writer=SummaryWriter(log_dir='logs/RNN')\n",
    "print(model_RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b58711b-53fc-4bec-b616-2807a5bb805b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN | Epoch: 1/5 | Iter: 819/819 | Error: 0/819 | Loss: 0.0532: 100%|\u001b[38;2;128;0;128m███████████████\u001b[0m| 819/819 [00:22<00:00, 36.90it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION | Epoch: 1/5 | Loss: 0.0541 | Accuracy: 0.4615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN | Epoch: 2/5 | Iter: 819/819 | Error: 0/819 | Loss: 0.0521: 100%|\u001b[38;2;128;0;128m███████████████\u001b[0m| 819/819 [00:20<00:00, 40.02it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION | Epoch: 2/5 | Loss: 0.0517 | Accuracy: 0.5350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN | Epoch: 3/5 | Iter: 819/819 | Error: 0/819 | Loss: 0.0517: 100%|\u001b[38;2;128;0;128m███████████████\u001b[0m| 819/819 [00:22<00:00, 36.71it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION | Epoch: 3/5 | Loss: 0.0518 | Accuracy: 0.5337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN | Epoch: 4/5 | Iter: 819/819 | Error: 0/819 | Loss: 0.0515: 100%|\u001b[38;2;128;0;128m███████████████\u001b[0m| 819/819 [00:20<00:00, 40.16it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION | Epoch: 4/5 | Loss: 0.0519 | Accuracy: 0.5330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN | Epoch: 5/5 | Iter: 819/819 | Error: 0/819 | Loss: 0.0513: 100%|\u001b[38;2;128;0;128m███████████████\u001b[0m| 819/819 [00:20<00:00, 40.63it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION | Epoch: 5/5 | Loss: 0.0517 | Accuracy: 0.5357\n"
     ]
    }
   ],
   "source": [
    "best_Acc_RNN=0\n",
    "for epoch in range(epochs):\n",
    "    trainer.train(model_RNN, train_loader_sentiment, epoch, epochs, writer, criterion, optimizer_RNN, device)\n",
    "    val_loss, val_acc = trainer.validation(model_RNN, val_loader_sentiment, criterion, device)\n",
    "    print(f\"VALIDATION | Epoch: {epoch+1}/{epochs} | Loss: {val_loss:.4f} | Accuracy: {val_acc:.4f}\")\n",
    "    writer.add_scalar('Val/Loss', val_loss, epoch+1)\n",
    "    writer.add_scalar('Val/Acc', val_acc, epoch+1)\n",
    "    checkpoint = {\n",
    "        'model_state_dict': model_RNN.state_dict(),\n",
    "        'epoch': epoch+1,\n",
    "        'optimizer_state_dict': optimizer_RNN.state_dict()\n",
    "    }\n",
    "    os.makedirs('model/RNN', exist_ok=True)\n",
    "    torch.save(checkpoint, os.path.join('model/RNN', 'last.pt'))\n",
    "    if val_acc>best_Acc_RNN:\n",
    "        torch.save(checkpoint, os.path.join('model/RNN', 'best.pt'))\n",
    "        best_Acc_RNN=val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745e2170-d840-4006-8a12-ed08807edbff",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc5d30a-53dd-4de5-bc5a-66ddae340dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5290482076637825,\n",
       " 'precision': 0.9336638944854555,\n",
       " 'recall': 0.5290482076637825,\n",
       " 'f1-score': 0.6466456879865078,\n",
       " 'confusion_matrix': array([[ 71,   0, 676],\n",
       "        [  4,   0,  68],\n",
       "        [ 14,   0, 785]], dtype=int64)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_RNN_on_test=trainer.evaluate(model_RNN, test_loader_sentiment, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "result_RNN_on_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a811da2-4804-4d70-8d49-ff20aa6fa768",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6896a963-84da-4309-96cd-70f01ddcd44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch. nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from build_model.build_lstm import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from training.trainer import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce92d6d-202e-4e1a-9629-82a196b3f04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_LSTM=LSTM(vocab_size=5000, embedding_dim=128, num_layers=2, activation=None, batch_normalization=True, bidirectional=False,output_dim=3).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_LSTM = optim.Adam(model_LSTM.parameters(), lr=0.001)\n",
    "trainer = trainer()\n",
    "log_dir = 'logs/RNN'\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "print(model_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84477fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN | Epoch: 1/5 | Iter: 819/819 | Error: 0/819 | Loss: 0.0348: 100%|\u001b[38;2;128;0;128m███████████████\u001b[0m| 819/819 [00:29<00:00, 27.46it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST | Epoch: 1/5 | Loss: 0.0230 | Accuracy: 0.8826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN | Epoch: 2/5 | Iter: 819/819 | Error: 0/819 | Loss: 0.0204: 100%|\u001b[38;2;128;0;128m███████████████\u001b[0m| 819/819 [00:39<00:00, 20.70it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST | Epoch: 2/5 | Loss: 0.0174 | Accuracy: 0.9100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN | Epoch: 3/5 | Iter: 819/819 | Error: 0/819 | Loss: 0.0162: 100%|\u001b[38;2;128;0;128m███████████████\u001b[0m| 819/819 [00:33<00:00, 24.18it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST | Epoch: 3/5 | Loss: 0.0169 | Accuracy: 0.9148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN | Epoch: 4/5 | Iter: 819/819 | Error: 0/819 | Loss: 0.0138: 100%|\u001b[38;2;128;0;128m███████████████\u001b[0m| 819/819 [00:32<00:00, 25.48it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST | Epoch: 4/5 | Loss: 0.0203 | Accuracy: 0.9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN | Epoch: 5/5 | Iter: 819/819 | Error: 0/819 | Loss: 0.0112: 100%|\u001b[38;2;128;0;128m███████████████\u001b[0m| 819/819 [00:31<00:00, 25.63it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST | Epoch: 5/5 | Loss: 0.0179 | Accuracy: 0.9135\n"
     ]
    }
   ],
   "source": [
    "epochs=5\n",
    "best_acc=0\n",
    "for epoch in range(epochs):\n",
    "    trainer.train(model_LSTM, train_loader_sentiment, epoch, epochs, writer, criterion, optimizer_LSTM, device)\n",
    "    val_loss, val_acc = trainer.validation(model_LSTM, val_loader_sentiment, criterion, device)\n",
    "    print(f\"TEST | Epoch: {epoch+1}/{epochs} | Loss: {val_loss:.4f} | Accuracy: {val_acc:.4f}\")\n",
    "    writer.add_scalar('Val/Loss', val_loss, epoch+1)\n",
    "    writer.add_scalar('Val/Acc', val_acc, epoch+1)\n",
    "    checkpoint = {\n",
    "        'model_state_dict': model_LSTM.state_dict(),\n",
    "        'epoch': epoch+1,\n",
    "        'opimizer_state_dict': optimizer_LSTM.state_dict(),\n",
    "    }\n",
    "    os.makedirs('model/LSTM', exist_ok=True)\n",
    "    torch.save(checkpoint, os.path.join('model/LSTM','last.pt'))\n",
    "    if val_acc>best_acc:\n",
    "        torch.save(checkpoint, os.path.join('model/LSTM','best.pt'))\n",
    "        best_acc=val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2033e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9023485784919654,\n",
       " 'precision': 0.9016187811436869,\n",
       " 'recall': 0.9023485784919654,\n",
       " 'f1-score': 0.9018738644200714,\n",
       " 'confusion_matrix': array([[693,  22,  32],\n",
       "        [ 22,  34,  16],\n",
       "        [ 47,  19, 733]], dtype=int64)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_LSTM_on_test=trainer.evaluate(model_LSTM, test_loader_sentiment, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "result_LSTM_on_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4a1bb8",
   "metadata": {},
   "source": [
    "## BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9826f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch. nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from build_model.build_lstm import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from training.trainer import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef0bba2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'trainer' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m      4\u001b[0m optimizer_BiLSTM \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model_BiLSTM\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m log_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogs/RNN\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(log_dir):\n",
      "\u001b[1;31mTypeError\u001b[0m: 'trainer' object is not callable"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_BiLSTM=LSTM(vocab_size=5000, embedding_dim=128, num_layers=2, activation=None, batch_normalization=True, bidirectional=True,output_dim=3).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_BiLSTM = optim.Adam(model_BiLSTM.parameters(), lr=0.001)\n",
    "trainer = trainer()\n",
    "log_dir = 'logs/RNN'\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "print(model_BiLSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac275b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[38;2;128;0;128m                                                                                           \u001b[0m| 0/819 [00:00<?, ?it/s]\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN | Epoch: 1/5 | Iter: 819/819 | Error: 0/819 | Loss: 0.0329: 100%|\u001b[38;2;128;0;128m███████████████\u001b[0m| 819/819 [00:40<00:00, 20.30it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST | Epoch: 1/5 | Loss: 0.0202 | Accuracy: 0.8990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN | Epoch: 2/5 | Iter: 819/819 | Error: 0/819 | Loss: 0.0200: 100%|\u001b[38;2;128;0;128m███████████████\u001b[0m| 819/819 [00:46<00:00, 17.61it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST | Epoch: 2/5 | Loss: 0.0192 | Accuracy: 0.9073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN | Epoch: 3/5 | Iter: 819/819 | Error: 0/819 | Loss: 0.0161: 100%|\u001b[38;2;128;0;128m███████████████\u001b[0m| 819/819 [00:50<00:00, 16.09it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST | Epoch: 3/5 | Loss: 0.0168 | Accuracy: 0.9114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN | Epoch: 4/5 | Iter: 819/819 | Error: 0/819 | Loss: 0.0123: 100%|\u001b[38;2;128;0;128m███████████████\u001b[0m| 819/819 [00:46<00:00, 17.65it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST | Epoch: 4/5 | Loss: 0.0177 | Accuracy: 0.9162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN | Epoch: 5/5 | Iter: 819/819 | Error: 0/819 | Loss: 0.0100: 100%|\u001b[38;2;128;0;128m███████████████\u001b[0m| 819/819 [00:41<00:00, 19.66it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST | Epoch: 5/5 | Loss: 0.0186 | Accuracy: 0.9128\n"
     ]
    }
   ],
   "source": [
    "epochs=5\n",
    "best_acc=0\n",
    "for epoch in range(epochs):\n",
    "    trainer.train(model_BiLSTM, train_loader_sentiment, epoch, epochs, writer, criterion, optimizer_BiLSTM, device)\n",
    "    val_loss, val_acc = trainer.validation(model_BiLSTM, val_loader_sentiment, criterion, device)\n",
    "    print(f\"TEST | Epoch: {epoch+1}/{epochs} | Loss: {val_loss:.4f} | Accuracy: {val_acc:.4f}\")\n",
    "    writer.add_scalar('Val/Loss', val_loss, epoch+1)\n",
    "    writer.add_scalar('Val/Acc', val_acc, epoch+1)\n",
    "    checkpoint = {\n",
    "        'model_state_dict': model_BiLSTM.state_dict(),\n",
    "        'epoch': epoch+1,\n",
    "        'opimizer_state_dict': optimizer_BiLSTM.state_dict(),\n",
    "    }\n",
    "    os.makedirs('model/BiLSTM', exist_ok=True)\n",
    "    torch.save(checkpoint, os.path.join('model/BiLSTM','last.pt'))\n",
    "    if val_acc>best_acc:\n",
    "        torch.save(checkpoint, os.path.join('model/BiLSTM','best.pt'))\n",
    "        best_acc=val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8b4e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9054388133498146,\n",
       " 'precision': 0.9102988977402795,\n",
       " 'recall': 0.9054388133498146,\n",
       " 'f1-score': 0.9076282818423385,\n",
       " 'confusion_matrix': array([[690,  18,  39],\n",
       "        [ 24,  29,  19],\n",
       "        [ 43,  10, 746]], dtype=int64)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_BiLSTM_on_test=trainer.evaluate(model_BiLSTM, test_loader_sentiment, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "result_BiLSTM_on_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cbe32c-6dc0-4ab8-9918-7cc376d0af57",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9357a20-c597-412c-b26f-37a1594a6249",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90797e72-9d1e-4023-bb93-5ce97469ac88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU(\n",
      "  (embedding): Embedding(5000, 128)\n",
      "  (gru): GRU(128, 64, num_layers=2, batch_first=True, dropout=0.2)\n",
      "  (dense1): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (dense2): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from build_model.build_gru import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from training.trainer import *\n",
    "import os\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_GRU=GRU(vocab_size=5000, embedding_dim=128, num_layers=2, activation=None, batch_normalization=True, bidirectional=False,output_dim=3).to(device)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer_GRU=optim.Adam(model_GRU.parameters(), lr=0.001)\n",
    "epochs=5\n",
    "trainer=trainer()\n",
    "log_dir='logs/GRU'\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "print(model_GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f257a3c1-461b-4664-98c0-41a7923ea99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from build_model.build_gru import *\n",
    "\n",
    "model_GRU=GRU(vocab_size=5000, embedding_dim=128, num_layers=2, activation=None, batch_normalization=True, bidirectional=False, output_dim=3)\n",
    "with open('model_architecture/GRU.pkl','wb') as f:\n",
    "    pickle.dump(model_GRU, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea76b24d-c857-475c-b965-0c0985e1fff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN | Epoch: 1/5 | Iter: 819/819 | Error: 0/819 | Loss: 0.0313: 100%|\u001b[38;2;128;0;128m███████████████\u001b[0m| 819/819 [00:40<00:00, 20.31it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST | Epoch: 1/5 | Loss: 0.0202 | Accuracy: 0.8929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN | Epoch: 2/5 | Iter: 819/819 | Error: 0/819 | Loss: 0.0191: 100%|\u001b[38;2;128;0;128m███████████████\u001b[0m| 819/819 [00:44<00:00, 18.54it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST | Epoch: 2/5 | Loss: 0.0176 | Accuracy: 0.9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN | Epoch: 3/5 | Iter: 819/819 | Error: 0/819 | Loss: 0.0153: 100%|\u001b[38;2;128;0;128m███████████████\u001b[0m| 819/819 [00:45<00:00, 18.07it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST | Epoch: 3/5 | Loss: 0.0176 | Accuracy: 0.9038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN | Epoch: 4/5 | Iter: 819/819 | Error: 0/819 | Loss: 0.0124: 100%|\u001b[38;2;128;0;128m███████████████\u001b[0m| 819/819 [00:45<00:00, 18.19it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST | Epoch: 4/5 | Loss: 0.0183 | Accuracy: 0.9107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN | Epoch: 5/5 | Iter: 819/819 | Error: 0/819 | Loss: 0.0102: 100%|\u001b[38;2;128;0;128m███████████████\u001b[0m| 819/819 [00:51<00:00, 15.91it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST | Epoch: 5/5 | Loss: 0.0184 | Accuracy: 0.9141\n"
     ]
    }
   ],
   "source": [
    "best_acc=0\n",
    "for epoch in range(epochs):\n",
    "    trainer.train(model_GRU, train_loader_sentiment, epoch, epochs, writer, criterion, optimizer_GRU, device)\n",
    "    val_loss, val_acc = trainer.validation(model_GRU, val_loader_sentiment, criterion, device)\n",
    "    print(f\"TEST | Epoch: {epoch+1}/{epochs} | Loss: {val_loss:.4f} | Accuracy: {val_acc:.4f}\")\n",
    "    writer.add_scalar('Val/Loss', val_loss, epoch+1)\n",
    "    writer.add_scalar('Val/Acc', val_acc, epoch+1)\n",
    "    checkpoint = {\n",
    "        'model_state_dict': model_GRU.state_dict(),\n",
    "        'epoch': epoch+1,\n",
    "        'opimizer_state_dict': optimizer_GRU.state_dict(),\n",
    "    }\n",
    "    os.makedirs('model/GRU', exist_ok=True)\n",
    "    torch.save(checkpoint, os.path.join('model/GRU','last.pt'))\n",
    "    if val_acc>best_acc:\n",
    "        torch.save(checkpoint, os.path.join('model/GRU','best.pt'))\n",
    "        best_acc=val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b2b080-96bc-45e4-b5df-a021cea41469",
   "metadata": {},
   "source": [
    "### Evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b761e16d-93ef-482e-b0d6-3919f9cf38d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.trainer import *\n",
    "from build_model.build_gru import *\n",
    "trainer=trainer()\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_GRU=GRU(vocab_size=5000, embedding_dim=128, num_layers=2, activation=None, batch_normalization=True, bidirectional=False).to(device)\n",
    "model_state_dict=torch.load('model/GRU/best.pt', map_location=device)\n",
    "model_GRU.load_state_dict(model_state_dict['model_state_dict'])\n",
    "result_GRU_on_test=trainer.evaluate(model_GRU, test_loader_sentiment, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583bcd57-cf9b-43a2-80c8-d53b71cf5634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GRU</th>\n",
       "      <td>0.914091</td>\n",
       "      <td>0.932634</td>\n",
       "      <td>0.914091</td>\n",
       "      <td>0.921216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy  precision    recall  f1-score\n",
       "GRU  0.914091   0.932634  0.914091  0.921216"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_GRU_df=pd.DataFrame({\n",
    "    'accuracy': result_GRU_on_test['accuracy'],\n",
    "    'precision': result_GRU_on_test['precision'],\n",
    "    'recall': result_GRU_on_test['recall'],\n",
    "    'f1-score': result_GRU_on_test['f1-score']\n",
    "}, index=['GRU'])\n",
    "result_GRU_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5459e32f-ed8a-485d-903a-6415d83a0e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 320x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cfs_matrix(result_GRU_on_test['confusion_matrix'], [\"Negative\", \"Neutral\", \"Positive\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1283264c-9287-4f1e-afe0-1d2d8b459b63",
   "metadata": {},
   "source": [
    "### HyperParameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2df187e-58e0-4101-a182-10d8f7ff4914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SearchCV.randomizedSearchCv_GRU import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d96ebbd-2701-4654-ac7c-e08150b1de8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SearchCV.perform_randomSearch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f615c4b8-d09b-4ad0-a7e5-76a9737983a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint, uniform  # Import these for param_dist\n",
    "param_dist = {\n",
    "    'embedding_dim': randint(128, 256),\n",
    "    'num_layers': randint(1, 3),\n",
    "    'drop_out': uniform(0.2, 0.5),\n",
    "    'units':  randint(64, 128),\n",
    "    'activation': [None],\n",
    "    'batch_normalization': [True, False],\n",
    "    'bidirectional': [True, False],\n",
    "    'lr': uniform(0.0001, 0.01),\n",
    "    'epochs': randint(3, 5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339cf976-39ad-4cd4-8c85-8a7e084807b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapper = PytorchModelWrapper(vocab_size=5000, embedding_dim=128, num_layers=2,\n",
    "                                    drop_out=0.2,\n",
    "                                    units=64,\n",
    "                                    activation=None, \n",
    "                                    batch_normalization=True,\n",
    "                                    bidirectional=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7edfa5-1ac3-45a4-b33d-f695cf4959ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GRU model results after HyperParameters Tuning:\n",
      "\n",
      "Params: {'activation': None, 'batch_normalization': False, 'bidirectional': False, 'drop_out': 0.43213670417397704, 'embedding_dim': 196, 'epochs': 4, 'lr': 0.008929428540843271, 'num_layers': 2, 'units': 110} - Mean test score: 0.89 - Rank: 1\n",
      "\n",
      "Bests parameters for GRU model: {'activation': None, 'batch_normalization': False, 'bidirectional': False, 'drop_out': 0.43213670417397704, 'embedding_dim': 196, 'epochs': 4, 'lr': 0.008929428540843271, 'num_layers': 2, 'units': 110}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_params, best_model = perform_random_search_pytorch('GRU', model_wrapper, param_dist,\n",
    "                                                        train_dataset_sentiment[:]['numericalized_encode'],\n",
    "                                                        train_dataset_sentiment[:]['labels'],\n",
    "                                                        n_iter=1,\n",
    "                                                        cv=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf1a140",
   "metadata": {},
   "source": [
    "## Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "675e63e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc00321",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data['sentence']\n",
    "# Ghi dữ liệu vào file\n",
    "with open(\"corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in corpus:\n",
    "        f.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3e74ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordPiece\n",
    "from tokenizers.trainers import WordPieceTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "tokenizer = Tokenizer(WordPiece(unk_token=\"[UNK]\"))\n",
    "\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "trainer = WordPieceTrainer(vocab_size=5000,\n",
    "                           special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"]\n",
    ")\n",
    "\n",
    "files = [\"corpus.txt\"]  \n",
    "\n",
    "tokenizer.train(files, trainer)\n",
    "\n",
    "tokenizer.save(\"custom_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "172f9c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "tokenizer = Tokenizer.from_file(\"custom_tokenizer.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6819ee2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Masks: [[0, 1, 1, 1, 0, 0, 0, 0, 0, 0], [0, 1, 1, 1, 1, 1, 0, 0, 0, 0]]\n",
      "Padded Token IDs: [[0, 280, 361, 668, 0, 0, 0, 0, 0, 0], [0, 453, 1039, 308, 361, 1415, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize nhiều câu\n",
    "sentences = [\"Đây là một câu.\", \"Câu này dài hơn một chút.\"]\n",
    "encodings = tokenizer.encode_batch(sentences)\n",
    "\n",
    "# Thêm padding và truncation\n",
    "max_length = 10  # Độ dài tối đa\n",
    "\n",
    "padded_token_ids = [\n",
    "    encoding.ids + [0] * (max_length - len(encoding.ids)) if len(encoding.ids) < max_length else encoding.ids[:max_length]\n",
    "    for encoding in encodings\n",
    "]\n",
    "\n",
    "# Tạo attention mask\n",
    "attention_masks = [\n",
    "    [1 if token != 0 else 0 for token in tokens] for tokens in padded_token_ids\n",
    "]\n",
    "\n",
    "print(\"Attention Masks:\", attention_masks)\n",
    "\n",
    "\n",
    "print(\"Padded Token IDs:\", padded_token_ids)\n",
    "# Ví dụ: [[101, 234, 876, 112, 0, 0, 0, 0, 0, 0], [101, 876, 234, 789, 543, 0, 0, 0, 0, 0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a967ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, sentences, labels, tokenizer, max_length):\n",
    "        self.sentences=sentences\n",
    "        self.labels=labels\n",
    "        self.tokenizer=tokenizer\n",
    "        self.max_length=max_length\n",
    "        self.encodings=self.tokenizer.encode_batch(self.sentences)\n",
    "        print()\n",
    "        self.padded_token_ids = [\n",
    "            encoding.ids +[0]* (self.max_length - len(encoding.ids))\n",
    "            if len(encoding.ids) < self.max_length\n",
    "            else  encoding.ids[:self.max_length]\n",
    "            for encoding in self.encodings\n",
    "        ]\n",
    "        self.attention_masks = [\n",
    "            [1 if token !=0 else 0 for token in tokens] for tokens in self.padded_token_ids\n",
    "        ]\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Trả về một mẫu tại chỉ mục idx.\n",
    "        Args:\n",
    "            idx (int): Chỉ mục của mẫu.\n",
    "        Returns:\n",
    "            dict: Gồm input_ids, attention_mask, và label.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'sentences': self.sentences[idx],\n",
    "            'input_ids': torch.tensor(self.padded_token_ids[idx], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(self.attention_masks[idx], dtype=torch.long),\n",
    "            'label': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "137b3b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, sentences, labels, tokenizer, max_length, cls_token=\"[CLS]\", sep_token=\"[SEP]\"):\n",
    "        \"\"\"\n",
    "        Dataset tuỳ chỉnh.\n",
    "        Args:\n",
    "            sentences (list): Danh sách các câu.\n",
    "            labels (list): Danh sách nhãn.\n",
    "            tokenizer: Tokenizer với hàm encode_batch.\n",
    "            max_length (int): Độ dài tối đa của mỗi câu.\n",
    "            cls_token (str): Token bắt đầu câu.\n",
    "            sep_token (str): Token kết thúc câu.\n",
    "        \"\"\"\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.cls_token = cls_token\n",
    "        self.sep_token = sep_token\n",
    "\n",
    "        # Thêm token đặc biệt và mã hóa các câu\n",
    "        self.encodings = self.tokenizer.encode_batch(\n",
    "            [f\"{self.cls_token} {sentence} {self.sep_token}\" for sentence in self.sentences]\n",
    "        )\n",
    "\n",
    "        # Thêm padding và attention mask\n",
    "        self.padded_token_ids = [\n",
    "            encoding.ids + [0] * (self.max_length - len(encoding.ids))\n",
    "            if len(encoding.ids) < self.max_length\n",
    "            else encoding.ids[:self.max_length]\n",
    "            for encoding in self.encodings\n",
    "        ]\n",
    "        self.attention_masks = [\n",
    "            [1 if token != 0 else 0 for token in tokens] for tokens in self.padded_token_ids\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Trả về một mẫu tại chỉ mục idx.\n",
    "        Args:\n",
    "            idx (int): Chỉ mục của mẫu.\n",
    "        Returns:\n",
    "            dict: Gồm sentences, input_ids, attention_mask, và label.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'sentence': self.sentences[idx],\n",
    "            'input_ids': torch.tensor(self.padded_token_ids[idx], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(self.attention_masks[idx], dtype=torch.long),\n",
    "            'label': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69a70f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CustomDataset(X_train, y_train_sentiment, tokenizer, max_length=24)\n",
    "val_dataset = CustomDataset(X_val, y_val_sentiment, tokenizer, max_length=24)\n",
    "test_dataset = CustomDataset(X_test, y_test_sentiment, tokenizer, max_length=24)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "841323e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.state_dict().clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5c8d878",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class PhoBERTClassifier(nn.Module):\n",
    "    def __init__(self, phobert_model_name, num_labels):\n",
    "        super(PhoBERTClassifier, self).__init__()\n",
    "        self.phobert = AutoModel.from_pretrained(phobert_model_name)\n",
    "        self.classifier = nn.Linear(self.phobert.config.hidden_size, num_labels)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.phobert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        # Sử dụng embedding của token [CLS]\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]\n",
    "        logits = self.classifier(cls_output)\n",
    "        return logits\n",
    "\n",
    "model = PhoBERTClassifier(\"bert-base-uncased\", num_labels=3)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cb2b85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhoBERTClassifier(\n",
       "  (phobert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f34381df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số trọng số: 109484547\n",
      "Số trọng số huấn luyện: 109484547\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Tổng số trọng số: {total_params}\")\n",
    "print(f\"Số trọng số huấn luyện: {trainable_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b03f6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 75\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m---> 75\u001b[0m train_acc, train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m accuracy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     87\u001b[0m val_acc, val_loss \u001b[38;5;241m=\u001b[39m eval_model(\n\u001b[0;32m     88\u001b[0m     model,\n\u001b[0;32m     89\u001b[0m     val_loader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28mlen\u001b[39m(X_val)\n\u001b[0;32m     93\u001b[0m )\n",
      "Cell \u001b[1;32mIn[29], line 27\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples)\u001b[0m\n\u001b[0;32m     24\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     26\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 27\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:68\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     67\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    371\u001b[0m             )\n\u001b[1;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\adamw.py:184\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    171\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    174\u001b[0m         group,\n\u001b[0;32m    175\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    181\u001b[0m         state_steps,\n\u001b[0;32m    182\u001b[0m     )\n\u001b[1;32m--> 184\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\adamw.py:335\u001b[0m, in \u001b[0;36madamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    333\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[1;32m--> 335\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\adamw.py:466\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m--> 466\u001b[0m     \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amsgrad \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(params[i]):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for d in data_loader:\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        labels = d[\"label\"].to(device)\n",
    "        #print(labels.shape)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            labels = d[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "EPOCHS = 3\n",
    "\n",
    "loss_fn = CrossEntropyLoss().to(device)\n",
    "\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        len(X_train)\n",
    "    )\n",
    "\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        val_loader,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        len(X_val)\n",
    "    )\n",
    "\n",
    "    print(f'Val loss {val_loss} accuracy {val_acc}')\n",
    "\n",
    "    if val_acc > best_accuracy:\n",
    "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "        best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1ea609",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
